{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports And Consts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_COLUMNS = [\n",
    "    \"score\",\n",
    "    \"numberOfTruePositives\",\n",
    "    \"accuracy\",\n",
    "    \"precision\",\n",
    "    \"numberOfFeatures\",\n",
    "    \"model\",\n",
    "    \"model_parameters\",\n",
    "    \"feature_selector\",\n",
    "    \"selector_parameters\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functions\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "from sklearn.feature_selection import f_classif, mutual_info_classif\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load the training and test data in a format specified by task description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./Dataset/x_test.txt\") as file:\n",
    "    X_test = [[float(digit) for digit in line.split()] for line in file]\n",
    "\n",
    "\n",
    "with open(\"./Dataset/x_train.txt\") as file:\n",
    "    X_train = [[float(digit) for digit in line.split()] for line in file]\n",
    "\n",
    "\n",
    "with open(\"./Dataset/y_train.txt\") as file:\n",
    "    y_train = [[float(digit) for digit in line.split()] for line in file]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the X_test there are 500 features and 5000 observations, y_train contains 5000 values, X_train contains 500 features and 5000 observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test datapoints: 5000  features: 500\n",
      "X_train datapoints: 5000  features: 500\n",
      "y_train datapoints: 5000\n"
     ]
    }
   ],
   "source": [
    "print(\"X_test datapoints:\", len(X_test), \" features:\", len(X_test[0]))\n",
    "print(\"X_train datapoints:\", len(X_train), \" features:\", len(X_train[0]))\n",
    "print(\"y_train datapoints:\", len(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch 16\n",
    "## Consts\n",
    "RESULTS_FILENAME = \"./Results/Limited/results-16\"\n",
    "## Experiment\n",
    "### Parameters\n",
    "# HistGradientBoostingClassifier\n",
    "learning_rate = [0.1, 0.01]\n",
    "max_depth = [2, 3, 5, None]\n",
    "random_state = [42]\n",
    "max_features = [3, 5, 8, 1.0]\n",
    "l2_regularization = [0, 0.5, 0.8]\n",
    "histGradientBoostingParameters = functions.generateParameters(\n",
    "    [learning_rate, max_depth, random_state, max_features, l2_regularization], globals()\n",
    ")\n",
    "\n",
    "# LDA\n",
    "solver = [\"svd\", \"lsqr\"]\n",
    "shrinkage = [None, \"auto\"]\n",
    "n_components = [3, 5, 8, None]\n",
    "ldaParameters = functions.generateParameters(\n",
    "    [solver, shrinkage, n_components], globals()\n",
    ")\n",
    "\n",
    "\n",
    "# QDA\n",
    "reg_param = [0, 0.3, 0.5, 0.8]\n",
    "qdaParameters = functions.generateParameters([reg_param], globals())\n",
    "\n",
    "# KNN\n",
    "n_neighbors = [3, 5, 8]\n",
    "weights = [\"uniform\", \"distance\"]\n",
    "p = [1, 2]\n",
    "leaf_size = [15, 30, 50]\n",
    "knnParameters = functions.generateParameters(\n",
    "    [n_neighbors, weights, p, leaf_size], globals()\n",
    ")\n",
    "\n",
    "# SVM\n",
    "C = [0.5, 1.0, 1.5]\n",
    "kernel = [\"linear\", \"rbf\", \"sigmoid\", \"poly\"]\n",
    "svcParameters = functions.generateParameters([C, kernel], globals())\n",
    "\n",
    "# GradientBoostingClassifier\n",
    "loss = [\"exponential\"]\n",
    "learning_rate = [ 0.001]\n",
    "n_estimators = [800]\n",
    "min_samples_split = [2]\n",
    "min_samples_leaf = [5, 7]\n",
    "subsample = [1.0]\n",
    "max_depth = [5, 8 ]\n",
    "min_impurity_decrease = [1]\n",
    "random_state = [42]\n",
    "max_features = [None]\n",
    "ccp_alpha = [0]\n",
    "gradientBoostingParameters = functions.generateParameters(\n",
    "    [\n",
    "        loss,\n",
    "        learning_rate,\n",
    "        n_estimators,\n",
    "        subsample,\n",
    "        max_depth,\n",
    "        random_state,\n",
    "        max_features,\n",
    "        ccp_alpha,\n",
    "        min_samples_split,\n",
    "        min_samples_leaf,\n",
    "        min_impurity_decrease,\n",
    "    ],\n",
    "    globals(),\n",
    ")\n",
    "\n",
    "\n",
    "# MLPClassifier\n",
    "\n",
    "activation = [\"relu\", \"tanh\"]\n",
    "solver = [ \"adam\"]\n",
    "alpha = [ 0.01]\n",
    "learning_rate = [ \"adaptive\"]\n",
    "learning_rate_init = [0.01, 0.001]\n",
    "hidden_layer_sizes = [(100,), (50,), (20,)]\n",
    "max_iter = [1600]\n",
    "random_state = [42]\n",
    "mlpClassifierParameters = functions.generateParameters(\n",
    "    [\n",
    "        activation,\n",
    "        solver,\n",
    "        alpha,\n",
    "        learning_rate,\n",
    "        learning_rate_init,\n",
    "        hidden_layer_sizes,\n",
    "        max_iter,\n",
    "        random_state,\n",
    "    ],\n",
    "    globals()\n",
    ")\n",
    "# Voting?\n",
    "estimators = [\n",
    "    [\n",
    "        (\n",
    "            \"1\",\n",
    "            functions.GradientBoostingClassifier(\n",
    "                loss=\"exponential\",\n",
    "                learning_rate=0.01,\n",
    "                n_estimators=200,\n",
    "                random_state=42,\n",
    "            ),\n",
    "        ),\n",
    "        (\"2\", functions.MLPClassifier(max_iter=800, random_state=42)),\n",
    "        (\"3\", functions.QuadraticDiscriminantAnalysis()),\n",
    "    ]\n",
    "]\n",
    "voting = [\"soft\"]\n",
    "\n",
    "votingParameters = functions.generateParameters([estimators, voting], globals())\n",
    "\n",
    "# AdaBoost\n",
    "\n",
    "\n",
    "estimator = [functions.KNeighborsClassifier(n_neighbors=5), \n",
    "            functions.LinearDiscriminantAnalysis(),\n",
    "            functions.QuadraticDiscriminantAnalysis(),\n",
    "            ]\n",
    "n_estimators = [50]\n",
    "learning_rate = [0.1,0.01]\n",
    "random_state = [42]\n",
    "\n",
    "adaBoostParameters = functions.generateParameters(\n",
    "    [estimator, n_estimators, learning_rate, random_state], globals()\n",
    ")\n",
    "\n",
    "models = [\n",
    "    # {\"model\": functions.ModelType.LDA, \"parameters\": ldaParameters},\n",
    "    # {\"model\": functions.ModelType.QDA, \"parameters\": qdaParameters},\n",
    "    # {\"model\": functions.ModelType.KNN, \"parameters\": knnParameters},\n",
    "    # {\"model\": functions.ModelType.SVC, \"parameters\": svcParameters},\n",
    "    # {\n",
    "      #  \"model\": functions.ModelType.GradientBoosting,\n",
    "       #  \"parameters\": gradientBoostingParameters,\n",
    "    # },\n",
    "    # {\n",
    "    #     \"model\": functions.ModelType.HistGradientBoosting,\n",
    "    #     \"parameters\": histGradientBoostingParameters,\n",
    "    # },\n",
    "    {\"model\": functions.ModelType.MLPClassifier, \"parameters\": mlpClassifierParameters},\n",
    "    {\"model\": functions.ModelType.ADABoost, \"parameters\": adaBoostParameters},\n",
    "    # {\"model\": functions.ModelType.Voting, \"parameters\": votingParameters},\n",
    "]\n",
    "# KBest\n",
    "k = [2, 3]\n",
    "score_func = [mutual_info_classif]\n",
    "kBestParameters = functions.generateParameters([score_func, k], globals())\n",
    "\n",
    "# FPR\n",
    "\n",
    "# mutual_info_classif seems to break for FPR but maybe try to run these without StandardScaler?\n",
    "score_func = [f_classif]\n",
    "alpha = [0.01]\n",
    "fprParameters = functions.generateParameters([score_func, alpha], globals())\n",
    "\n",
    "\n",
    "# RFE\n",
    "estimator = [SVC(kernel=\"linear\")]\n",
    "n_features_to_select = [2, 3]\n",
    "step = [0.9]\n",
    "rfeParameters = functions.generateParameters(\n",
    "    [estimator, n_features_to_select, step], globals()\n",
    ")\n",
    "\n",
    "\n",
    "featureSelectors = [\n",
    "    {\"model\": functions.FeatureSelectorType.KBest, \"parameters\": kBestParameters},\n",
    "    #{\"model\": functions.FeatureSelectorType.FPR, \"parameters\": fprParameters},\n",
    "    #{\"model\": functions.FeatureSelectorType.RFE, \"parameters\": rfeParameters},\n",
    "]\n",
    "scalers = [\n",
    "    # {\"model\": functions.Scaler.NoScaling, \"parameters\": [{}]},\n",
    "    # {\"model\": functions.Scaler.Standard, \"parameters\": [{}]},\n",
    "    {\"model\": functions.Scaler.Robust, \"parameters\": [{}]},\n",
    "]\n",
    "\n",
    "degree = [2]\n",
    "\n",
    "polynomialParameters = functions.generateParameters([degree], globals())\n",
    "\n",
    "featureGenerators = [\n",
    "    {\"model\": functions.FeatureGenerator.NoFeatureGeneration, \"parameters\": [{}]},\n",
    "    {\n",
    "        \"model\": functions.FeatureGenerator.Polynomial,\n",
    "        \"parameters\": polynomialParameters,\n",
    "    },\n",
    "]\n",
    "### Conducting the experiment\n",
    "y_train_ravel = np.ravel(y_train, order=\"C\")\n",
    "y_train_ravel = y_train_ravel.astype(int)\n",
    "%%time\n",
    "results = functions.conductExperimentsWithScalersAndGenerators(\n",
    "    models=models,\n",
    "    featureSelectors=featureSelectors,\n",
    "    X_orig=X_train,\n",
    "    y_orig=y_train_ravel,\n",
    "    scalers=scalers,\n",
    "    featureGenerators=featureGenerators,\n",
    "    getLimitedScore=True,\n",
    "    limit=0.45,\n",
    "\n",
    ")\n",
    "with open(RESULTS_FILENAME, \"wb\") as f:\n",
    "    pickle.dump(results, f)\n",
    "## Results\n",
    "with open(RESULTS_FILENAME, \"rb\") as input_file:\n",
    "    results = pickle.load(input_file)\n",
    "resultsDf = pd.DataFrame(\n",
    "    results,\n",
    "    columns=functions.RESULTS_COLUMNS,\n",
    ")\n",
    "### Detailed Results\n",
    "%%time\n",
    "processedResultsDf, parameters = functions.extractParameterResultsArr(\n",
    "    resultsDf,\n",
    "    [models, featureSelectors, scalers, featureGenerators],\n",
    "    [\n",
    "        \"model_parameters\",\n",
    "        \"selector_parameters\",\n",
    "        \"scaler_parameters\",\n",
    "        \"feature_generator_parameters\",\n",
    "    ],\n",
    ")\n",
    "functions.drawParameterResultsBarplot(processedResultsDf, parameters)\n",
    "### Score/Accuracy by number of features\n",
    "functions.drawResultsPerNumberOfFeatures(processedResultsDf)\n",
    "### Final Results for Feature Selectors\n",
    "plt.title(\"Final comparison of feature selectors\")\n",
    "sns.boxplot(data=processedResultsDf, x=\"feature_selector\", y=\"score\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "sns.boxplot(data=processedResultsDf,x=\"model\",y=\"score\",hue=\"feature_generator\")\n",
    "sns.boxplot(data=processedResultsDf,x=\"model\",y=\"score\",hue=\"scaler\")\n",
    "### Final Results for Models\n",
    "plt.title(\"Final comparison of models\")\n",
    "sns.boxplot(data=processedResultsDf, x=\"model\", y=\"score\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "### Final Results\n",
    "%%time\n",
    "filteredDf = functions.filterDataframeByBestResults(processedResultsDf)\n",
    "processedResultsDf[processedResultsDf[\"scaler\"]==functions.Scaler.NoScaling.name].sort_values(by=\"score\",ascending=False).head(5)\n",
    "filteredDf['scaler']\n",
    "filteredDf['model_parameters'].to_numpy()\n",
    "filteredDf['feature_generator']\n",
    "filteredDf\n",
    "\n",
    "\n",
    "%%time\n",
    "filteredDf = functions.filterDataframeByBestResults(processedResultsDf)\n",
    "processedResultsDf[processedResultsDf[\"scaler\"]==functions.Scaler.NoScaling.name].sort_values(by=\"score\",ascending=False).head(5)\n",
    "filteredDf['scaler']\n",
    "filteredDf['model_parameters'].to_numpy()\n",
    "filteredDf['feature_generator']\n",
    "filteredDf\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
