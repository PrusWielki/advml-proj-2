{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes\n",
    "\n",
    "Emm I read the pdf and it's a bit hard to split this project into tasks tbh. From what I understood the goal, in short, is to achieve the best possible accuracy with least amount of features used. Whereas there is some reward for higher accuracy and penalty for number of features used so we need to find a proper balance. 5 different approaches should be used. It is a binary classification task. So I think we could:\n",
    "\n",
    "1. Find some best candidates methods for binary classification tasks with numeric features.\n",
    "2. One approach would be to iterate over the number of features starting from 1 (xd) and find the number that achieves the best score for each of the chosen methods\n",
    "3. We could also do some feature selection methods and try to find the best number of features that way.\n",
    "4. We could do some ensembling, maybe combining  models from the above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO:\n",
    "\n",
    "1. Find some good candidates for binary classification including ensembles\n",
    "    1. 5 different models\n",
    "2. Write a pipeline for testing and analysis of the results\n",
    "3. Write the report\n",
    "4. Prepare the presentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load the training and test data in a format specified by task description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./Dataset/x_test.txt') as file:\n",
    "    X_test = [[float(digit) for digit in line.split()] for line in file]\n",
    "\n",
    "\n",
    "with open('./Dataset/x_train.txt') as file:\n",
    "    X_train = [[float(digit) for digit in line.split()] for line in file]\n",
    "\n",
    "\n",
    "with open('./Dataset/y_train.txt') as file:\n",
    "    y_train = [[float(digit) for digit in line.split()] for line in file]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the X_test there are 500 features and 5000 observations, y_train contains 5000 values, X_train contains 500 features and 5000 observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test datapoints: 5000  features: 500\n",
      "X_train datapoints: 5000  features: 500\n",
      "y_train datapoints: 5000\n"
     ]
    }
   ],
   "source": [
    "print('X_test datapoints:',len(X_test),\" features:\",len(X_test[0]))\n",
    "print('X_train datapoints:',len(X_train),\" features:\",len(X_train[0]))\n",
    "print('y_train datapoints:',len(y_train))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Put here at least 5 different models, which can be including ensembles\n",
    "models = [LinearDiscriminantAnalysis(),QuadraticDiscriminantAnalysis()]\n",
    "# TODO: Put here corresponding model names, names You would like to see on charts etc\n",
    "modelNames = ['xd']\n",
    "# TODO: Put here selection techniques (Can be the same as in data exploration project 4 (I will do it - Patryk))\n",
    "featureSelectors=[]\n",
    "featureSelectorsNames=['xd']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Put here model parameters in the following format\n",
    "modelParameters=[{str(modelNames[0]):{'param1':5}}]\n",
    "# TODO: A dictionary with experiment function parameters (maybe things such as number of repetitions, maybe some parameters for )\n",
    "experimentParameters = [{\"param1\":5},]\n",
    "# TODO: Feature selector parameters\n",
    "featureSelectorsParameters=[{str(featureSelectorsNames[0]):{'param1':5}}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main experiment loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performExperiment(param1,X_train,y_train,X_test,model):\n",
    "    model.fit(X_train,y_train)\n",
    "    result = model.predict_proba(X_test)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conducting the experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "collect info about features used and the amount of predicted positive class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\prusak.patryk\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\prusak.patryk\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\prusak.patryk\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1.83 s\n",
      "Wall time: 3.92 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "results=[]\n",
    "for parameters in experimentParameters:\n",
    "    for model in models:\n",
    "        result = performExperiment(**parameters,X_train=X_train,y_train=y_train,X_test=X_test,model=model)\n",
    "        results.append(result)\n",
    "with open(\"./Results/results\", \"wb\") as f:\n",
    "    pickle.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.59509475, 0.40490525],\n",
       "       [0.47723719, 0.52276281],\n",
       "       [0.63522468, 0.36477532],\n",
       "       ...,\n",
       "       [0.68885676, 0.31114324],\n",
       "       [0.18292939, 0.81707061],\n",
       "       [0.35247262, 0.64752738]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: We are supposed to identify only 1000 people, so we need to find a way to handle that, \n",
    "# if we would implement our own model then we could modify the threshold\n",
    "# not sure how to handle it if we were to use scikit models - we could use predict_proba and modify the threshold so that only 1000 people remain\n",
    "len(results[0][results[0]>0.719])\n",
    "finalResult = np.sort(results[0][0])[::-1][:1000]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"./Results/results\", \"rb\") as input_file:\n",
    "     results = pickle.load(input_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: Process the results, some charts etc, maybe some correlations, line plots etc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
